{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages for data manupulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import random\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: set path for data placement \n",
    "#os.chdir(r'C:\\Users\\mshafin\\Desktop\\xavient_churn_project')\n",
    "#os.chdir(r'C:\\Users\\mohammad shafin\\Desktop\\xavient_churn_project')\n",
    "\n",
    "os.chdir(r'/home/mohnkhan/xavient_binary_balanced')\n",
    "random.seed(42)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: data loaded to a pandas dataframe\n",
    "\n",
    "df = pd.read_csv('telecom_churn_training.csv')\n",
    "df.info()\n",
    "df_length = df.shape[1]\n",
    "df_row = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of missing values in each column\n",
    "# sum True's\n",
    "\n",
    "print(\"Columnwise missing value count\")\n",
    "df.isnull().sum().plot.bar(figsize=(df_length, 4))\n",
    "#df[\"target\"].value_counts().plot.pie(figsize=(4, 4))\n",
    "#print(df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: set customer identification code and target variable\n",
    "\n",
    "customer_identity_code = 'customerID'\n",
    "target_code = 'Churn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index for customer identification code\n",
    "\n",
    "df = df.set_index(customer_identity_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify target variable\n",
    "\n",
    "df['target'] = df[target_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: set target labels\n",
    "\n",
    "label_target1 = 'Yes'\n",
    "label_target0 = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recode target levels\n",
    "\n",
    "def dependent_col(row):\n",
    "    if row['target'] == label_target1:\n",
    "        val = 1  # input\n",
    "    elif row['target'] == label_target0:\n",
    "        val = 0  # imput\n",
    "    else:\n",
    "        val = 2\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view recoded data in the target variable\n",
    "\n",
    "df['target'] = df.apply(dependent_col, axis=1)\n",
    "print(df.loc[:,['target','Churn']].head(5)) #check changes in target recoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep rows when target variable is finite\n",
    "\n",
    "start = df.shape[1]\n",
    "df = df[np.isfinite(df['target'])]\n",
    "finish = df.shape[1]\n",
    "print(\"The number of row/rows dropped because of missing target variable is \" + str(start-finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT droping initial target\n",
    "# when the target variable is identified and recoded it has to be removed by the program\n",
    "\n",
    "df = df.drop(['Churn'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target variable distibution\n",
    "\n",
    "df[\"target\"].value_counts().plot.pie(figsize=(4, 4))\n",
    "print(df.target.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: populate with columns, which is considered discrete or non continious\n",
    "# all categoies which have string input are categroized as object type in python by default\n",
    "\n",
    "object_columns = ['gender','SeniorCitizen','Partner','Dependents','PhoneService','MultipleLines','InternetService',\n",
    "                  'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies',\n",
    "                  'Contract','PaperlessBilling','PaymentMethod'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typecasting 'object' type on variables that may be populated with numbers, but are of non-continious nature such as gender\n",
    "\n",
    "for column in object_columns:\n",
    "    df[column] = df[column].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view levels per columns in the non-continious variable\n",
    "\n",
    "print(\"Value count of each level for datatype 'object'\")\n",
    "\n",
    "for column in object_columns:\n",
    "    print(column)\n",
    "    df[column].value_counts().plot.bar(figsize=(df_length/4, 2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object variables converted to categories for cat.codes\n",
    "\n",
    "object_columns = df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value imputation strategy: create a new level called 'UNKNOWN'\n",
    "\n",
    "print(\"The count of columns were successfully imputed with missing value indicator 'UKNOWN'\")\n",
    "\n",
    "for column in object_columns:\n",
    "    if df[column].dtypes==\"object\":\n",
    "        df[column] = df[column].fillna(\"UKNOWN\").astype('object')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing value imputation strategy: create a new level called 'UNKNOWN'\n",
    "\n",
    "for column in object_columns:\n",
    "    if df[column].dtypes==\"object\":\n",
    "        df[column] = df[column].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recoding categories to number with numerical and alphabatical order 0-1 and a-z, respectively\n",
    "\n",
    "df[object_columns] = df[object_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chisquare test function\n",
    "\n",
    "import scipy.stats as scs\n",
    "\n",
    "def categories(series):\n",
    "    return range(int(series.min()), int(series.max()) + 1)\n",
    "\n",
    "def chi_square_of_df_cols(df, col1, col2):\n",
    "    df_col1, df_col2 = df[col1], df[col2]\n",
    "\n",
    "    result = [[sum((df_col1 == cat1) & (df_col2 == cat2))\n",
    "               for cat2 in categories(df_col2)]\n",
    "              for cat1 in categories(df_col1)]\n",
    "\n",
    "    return scs.chi2_contingency(result)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check chisquare test for category variables\n",
    "\n",
    "object_columns_final = []\n",
    "chi_square_pvalue_final = []\n",
    "for column in object_columns:\n",
    "    chisquare_pvalue = round(chi_square_of_df_cols(df, column, 'target').astype('float64'),3)\n",
    "    #if chi_square_of_df_cols(df, column, 'target') <= 0.05:\n",
    "    object_columns_final.append(column)\n",
    "    chi_square_pvalue_final.append(chisquare_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame create to view column wise p-value with respect to the target\n",
    "\n",
    "df_catname = pd.DataFrame({'feature_name':object_columns_final})\n",
    "df_pvalue = pd.DataFrame({'p-value':chi_square_pvalue_final})\n",
    "\n",
    "frames = [df_catname,df_pvalue]\n",
    "print(pd.concat(frames,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final list of categorical variables that survive the p-value check in the chi square test\n",
    "\n",
    "object_columns_final = []\n",
    "\n",
    "for column in object_columns:\n",
    "    chisquare_pvalue = round(chi_square_of_df_cols(df, column, 'target').astype('float64'),3)\n",
    "    if chi_square_of_df_cols(df, column, 'target') <= 0.05:\n",
    "        object_columns_final.append(column)\n",
    "print(\"Categorical variables selected for modeling post chi-square test\")\n",
    "print(object_columns_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check near zero variance\n",
    "\n",
    "object_columns_final_nz = []\n",
    "object_columns_final_variance = []\n",
    "\n",
    "for column in object_columns_final:\n",
    "    object_columns_variance = df[column].var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)\n",
    "    #if  feature_columns_variance > 0.00:\n",
    "    object_columns_final_nz.append(column)\n",
    "    object_columns_final_variance.append(object_columns_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_object_columns_final_nz = pd.DataFrame({'feature_name':object_columns_final_nz})\n",
    "df_variance = pd.DataFrame({'variance':object_columns_final_variance})\n",
    "frames = [df_object_columns_final_nz,df_variance]\n",
    "\n",
    "print(pd.concat(frames,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check near zero variance\n",
    "\n",
    "object_columns_final_nz = []\n",
    "object_columns_final_variance = []\n",
    "\n",
    "for column in object_columns_final:\n",
    "    object_columns_variance = df[column].var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)\n",
    "    if  object_columns_variance > 0.01:\n",
    "        object_columns_final_nz.append(column)\n",
    "        object_columns_final_variance.append(object_columns_variance)\n",
    "print(\"Categorical variables with variance above 0.01\")\n",
    "print(object_columns_final_nz)\n",
    "print(\"number of categorical columns: \"+ str(len(object_columns_final_nz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving categorical columns for scoring\n",
    "\n",
    "import pickle\n",
    "object_columns_final_nz_index = object_columns_final_nz\n",
    "\n",
    "pickle_out_cat = open(\"object_columns_final_nz.pickle\",\"wb\")\n",
    "pickle.dump(object_columns_final_nz_index, pickle_out_cat)\n",
    "pickle_out_cat.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numeric columns for scoring\n",
    "import pickle\n",
    "pickle_in_cat = open(\"object_columns_final_nz.pickle\",\"rb\")\n",
    "object_columns_final_nz_index = pickle.load(pickle_in_cat)\n",
    "len(object_columns_final_nz_index)\n",
    "#df[object_columns_final_nz_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: populate with numeric columns\n",
    "# missing value treatments\n",
    "\n",
    "numeric_columns_mean = ['MonthlyCharges','TotalCharges'] # impute missing numeric columns with mean\n",
    "\n",
    "# impute missing numeric columns with zero\n",
    "\n",
    "numeric_columns_zero = ['tenure'] # populate with numeric columns\n",
    "\n",
    "scale_columns = numeric_columns_mean + numeric_columns_zero\n",
    "length = len(scale_columns) # for figure width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[scale_columns].plot.box(figsize=(length*2,4))\n",
    "print(\"Check for continous variable scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mean imputation\n",
    "\n",
    "for column in numeric_columns_mean:\n",
    "    if df[column].dtypes in [\"int64\",\"float64\"] :\n",
    "        df[column] = df[column].fillna(df[column].mean())\n",
    "\n",
    "# for 0 imputation\n",
    "\n",
    "for column in numeric_columns_zero:\n",
    "    if df[column].dtypes in [\"int64\",\"float64\"] :\n",
    "        df[column] = df[column].fillna(0)\n",
    "\n",
    "# append all numerical columns\n",
    "\n",
    "scale_columns = numeric_columns_mean + numeric_columns_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the numerical variables to remove outliers\n",
    "from sklearn.preprocessing import scale\n",
    "for column in scale_columns:\n",
    "    if df[column].dtypes in [\"int64\",\"float64\"] :\n",
    "        df[column] = scale(df[column].astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scaled continious variables\")\n",
    "df[scale_columns].plot.box(figsize=(length*2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check near zero variance\n",
    "\n",
    "scale_columns_final_nz = []\n",
    "scale_columns_variance_final = []\n",
    "\n",
    "for column in scale_columns:\n",
    "    scale_columns_variance = df[column].var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)\n",
    "    #if  feature_columns_variance > 0.00:\n",
    "    scale_columns_final_nz.append(column)\n",
    "    scale_columns_variance_final.append(scale_columns_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scale_columns_final = pd.DataFrame({'feature_name':scale_columns_final_nz})\n",
    "df_variance = pd.DataFrame({'variance':scale_columns_variance_final})\n",
    "frames = [df_scale_columns_final,df_variance]\n",
    "\n",
    "print(pd.concat(frames,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check near zero variance\n",
    "\n",
    "scale_columns_final_nz = []\n",
    "scale_columns_variance_final = []\n",
    "\n",
    "for column in scale_columns:\n",
    "    scale_columns_variance = df[column].var(axis=None, skipna=None, level=None, ddof=1, numeric_only=None)\n",
    "    if  scale_columns_variance > 0.01:\n",
    "        scale_columns_final_nz.append(column)\n",
    "        scale_columns_variance_final.append(scale_columns_variance)\n",
    "print(\"numeric variables with variance above 0.01\")\n",
    "print(scale_columns_final_nz)\n",
    "print(\"number of numeric columns: \"+ str(len(scale_columns_final_nz)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving numeric columns for scoring\n",
    "import pickle\n",
    "\n",
    "scale_columns_final_nz_index = scale_columns_final_nz\n",
    "pickle_out_num = open(\"scale_columns_final_nz.pickle\",\"wb\")\n",
    "pickle.dump(scale_columns_final_nz_index, pickle_out_num)\n",
    "pickle_out_num.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load numeric columns for scoring\n",
    "import pickle\n",
    "\n",
    "pickle_in_num = open(\"scale_columns_final_nz.pickle\",\"rb\")\n",
    "scale_columns_final_nz_index = pickle.load(pickle_in_num)\n",
    "len(scale_columns_final_nz_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features for modeling objective\n",
    "\n",
    "target_column = ['target']\n",
    "feature_columns = scale_columns_final_nz + object_columns_final_nz\n",
    "print(\"target_column: \" + str(target_column))\n",
    "print(\"feature_columns: \" + str(feature_columns))\n",
    "print(\"dataframe shape: \" + str(df[feature_columns].shape))\n",
    "fig_length = df[feature_columns].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_features, test_features,\\\n",
    "training_target, test_target, = train_test_split(df[feature_columns].values, df[target_column].values.ravel(), test_size = .1, random_state=12)\n",
    "training_features.shape, test_features.shape, training_target.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_val, y_train, y_val \\\n",
    "= train_test_split(training_features, training_target, test_size = .1, random_state=12)\n",
    "\n",
    "# Using smote to increase the number of under-represented class\n",
    "sm = SMOTE(random_state = 12, ratio = 'minority')\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "X_train_res.shape, y_train_res.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics for model evaluation\n",
    "\n",
    "from sklearn.metrics import recall_score,accuracy_score,confusion_matrix,classification_report,precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# create function to evaluate model performance\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    cohen_kappa = cohen_kappa_score(y_test, y_pred, sample_weight=None)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"accuracy :\" +str(accuracy))\n",
    "    print(\"cohen_kappa :\" +str(cohen_kappa))\n",
    "    print(\"recall :\" +str(recall))\n",
    "    print(\" tn, fp, fn, tp :\" )\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"matrix :\")\n",
    "    print(matrix)\n",
    "    print(\"report :\")\n",
    "    print(report)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, Activation\n",
    "\n",
    "# fix the input dimenstion to number of feature terms\n",
    "input_dimenation = int(training_features.shape[1])\n",
    "\n",
    "# create the output dimenstion\n",
    "output = 1\n",
    "\n",
    "# create the batch size\n",
    "batch = int(round(df.shape[0]/10,0))\n",
    "\n",
    "# epoch\n",
    "epoch = 100\n",
    "\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dimenation, input_dim=input_dimenation, activation='relu'))\n",
    "    model.add(Dense(output, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate list of models  \n",
    "models = []\n",
    "models.append(('XGB', XGBClassifier(n_estimators = 500,learning_rate=.1, random_state=21)))\n",
    "models.append(('GBM', GradientBoostingClassifier(n_estimators = 500,learning_rate=.1, random_state=21)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators = 500 ,random_state=21)))\n",
    "models.append(('DT', DecisionTreeClassifier(splitter='random', random_state=21)))\n",
    "models.append(('ADA', AdaBoostClassifier(n_estimators = 500,learning_rate=.1, random_state=21)))\n",
    "models.append(('LM', LogisticRegression(multi_class = 'ovr', solver='saga', random_state=21)))\n",
    "#models.append(('TF', KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch, verbose=0))) \n",
    "\n",
    "# check model performance\n",
    "results = []\n",
    "names = []\n",
    "seed = 7\n",
    "msgall = []\n",
    "scoring='accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 10, random_state=seed)\n",
    "    #cv_results = cross_val_score(model, X_train_res, y_train_res, cv=kfold, scoring = scoring)\n",
    "    cv_results = cross_val_score(model, training_features, training_target, cv=kfold, scoring = scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = (name, cv_results.mean(), cv_results.std())\n",
    "    print (msg)\n",
    "    msgall.append(msg)\n",
    "\n",
    "# compare algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"algorithm comparision\")\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ensemble models\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid for randomizedsearch\n",
    "GBM = GradientBoostingClassifier()\n",
    "\n",
    "# Number of iterations needed\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, num = 10)]\n",
    "learning_rate = [0.1, 0.05, 0.02, 0.01]\n",
    "max_features = ['sqrt','auto','log2','None','1','0.1']\n",
    "loss = ['deviance', 'exponential']\n",
    "max_depth = [4, 6, 8]\n",
    "criterion = ['friedman_mse']\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [20,50,100,150]\n",
    "random_state = [21]\n",
    "\n",
    "# Create the random grid\n",
    "\n",
    "random_grid_gbm = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'loss':loss,\n",
    "               'max_depth': max_depth,\n",
    "               'criterion': criterion,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'random_state': random_state}\n",
    "pprint(random_grid_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = GradientBoostingClassifier()\n",
    "# Random search of parameters, using 10 fold cross validation,\n",
    "# search across 50 different combinations, and use all available cores\n",
    "#gbm_smote = RandomizedSearchCV(estimator = GBM, param_distributions = random_grid_gbm, n_iter = 5, cv = 3, verbose=1, random_state=42, n_jobs = -1)\n",
    "gbm = RandomizedSearchCV(estimator = GBM, param_distributions = random_grid_gbm, n_iter = 5, cv = 10, verbose=1, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the gbm SMOTE model\n",
    "#gbm_smote.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "#gbm_smote_accuracy = evaluate(gbm_smote,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the gbm model without SMOTE\n",
    "\n",
    "gbm.fit(training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "gbm_accuracy = evaluate(gbm,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance plots\n",
    "\n",
    "#print(\"gbm with SMOTE feature importance\")\n",
    "feature_names=df.drop(['target'],axis=1).columns\n",
    "#feature_importance = gbm_smote.best_estimator_.feature_importances_\n",
    "#sorted_idx = np.argsort(feature_importance)\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.figure(figsize=(10,fig_length/3))\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, feature_names[sorted_idx])\n",
    "#feature_names[sorted_idx]\n",
    "#plt.show()\n",
    "\n",
    "print(\"gbm without SMOTE feature importance\")\n",
    "feature_importance = gbm.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(10,fig_length/3))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "feature_names[sorted_idx]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "random_state = [21]\n",
    "\n",
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'random_state':random_state}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 10 fold cross validation,\n",
    "# search across 50 different combinations, and use all available cores\n",
    "\n",
    "#rf_smote = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 10, verbose=1, random_state=42, n_jobs = -1)\n",
    "rf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 10, verbose=0, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "\n",
    "#rf_smote.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "#rf_smote_accuracy = evaluate(rf_smote,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "\n",
    "rf.fit(training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "rf_accuracy = evaluate(rf,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance plots\n",
    "\n",
    "#print(\"rf with SMOTE feature importance\")\n",
    "feature_names=df.drop(['target'],axis=1).columns\n",
    "#feature_importance = rf_smote.best_estimator_.feature_importances_\n",
    "#sorted_idx = np.argsort(feature_importance)\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.figure(figsize=(10,fig_length/3))\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, feature_names[sorted_idx])\n",
    "#feature_names[sorted_idx]\n",
    "#plt.show()\n",
    "\n",
    "print(\"rf without SMOTE feature importance\")\n",
    "feature_importance = rf.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(10,fig_length/3))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "feature_names[sorted_idx]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "\n",
    "ADA = AdaBoostClassifier()\n",
    "\n",
    "# Number of iterations needed\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, num = 10)]\n",
    "learning_rate = [0.1, 0.05, 0.02, 0.01]\n",
    "algorithm  = ['SAMME', 'SAMME.R']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_state = [21]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid_ada = {'n_estimators': n_estimators,\n",
    "                   'learning_rate': learning_rate,\n",
    "                   'algorithm':algorithm,\n",
    " #                 'max_depth': max_depth,\n",
    " #                 'min_samples_leaf': min_samples_leaf,\n",
    "                   'random_state': random_state}\n",
    "pprint(random_grid_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "ada = AdaBoostClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "#ada_smote = RandomizedSearchCV(estimator = ada, param_distributions = random_grid_ada, n_iter = 5, cv = 10, verbose=1, random_state=42, n_jobs = -1)\n",
    "ada = RandomizedSearchCV(estimator = ada, param_distributions = random_grid_ada, n_iter = 5, cv = 10, verbose=0, random_state=42, n_jobs = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "\n",
    "#ada_smote.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "#ada_smote_accuracy = evaluate(ada_smote,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "\n",
    "ada.fit(training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "ada_accuracy = evaluate(ada,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance plots\n",
    "\n",
    "#print(\"ada with SMOTE feature importance\")\n",
    "feature_names=df.drop(['target'],axis=1).columns\n",
    "#feature_importance = ada_smote.best_estimator_.feature_importances_\n",
    "#sorted_idx = np.argsort(feature_importance)\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.figure(figsize=(10,fig_length/3))\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, feature_names[sorted_idx])\n",
    "#feature_names[sorted_idx]\n",
    "#plt.show()\n",
    "\n",
    "print(\"ada without SMOTE feature importance\")\n",
    "feature_importance = ada.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(10,fig_length/3))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "feature_names[sorted_idx]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model on the Sonar Dataset\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the input dimenstion to number of feature terms\n",
    "input_dimenation = X_train_res.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: model parameters\n",
    "epochs_input = 100\n",
    "batch_size_input = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dimenation, input_dim=input_dimenation, kernel_initializer='normal', activation='relu'))#, kernel_constraint=maxnorm(3)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(input_dimenation, kernel_initializer='normal', activation='relu'))#, kernel_constraint=maxnorm(2)))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(output, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    sgd = SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "#model_smote = KerasClassifier(build_fn = create_model, epochs = epochs_input, batch_size = batch_size_input, verbose = 1)\n",
    "# Fit the model\n",
    "#model_smote.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "#tf_accuracy = evaluate(model_smote,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, epochs = epochs_input, batch_size = batch_size_input, verbose = 1)\n",
    "# Fit the model\n",
    "model.fit(training_features, training_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "#tf_accuracy = evaluate(model,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import scipy.stats as st\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(200, 2000, num = 10)]\n",
    "learning_rate = [0.1, 0.05, 0.02, 0.01]\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "random_state = [21]\n",
    "\n",
    "# Create the random grid\n",
    "\n",
    "# First create the base model to tune\n",
    "n_estimators = [int(x) for x in np.linspace(3, 40, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "random_state=[21]\n",
    "params = {  \n",
    "    'n_estimators': n_estimators,\n",
    "    'learning_rate': learning_rate,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "    'random_state':random_state\n",
    "}\n",
    "\n",
    "xgbclass = XGBClassifier(nthreads=-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = RandomizedSearchCV(xgbclass, params, n_jobs=1)  \n",
    "gs.fit(training_features, training_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on test set\n",
    "\n",
    "xgb_accuracy = evaluate(gs,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance plots\n",
    "\n",
    "#print(\"XGBOOST with SMOTE feature importance\")\n",
    "feature_names=df.drop(['target'],axis=1).columns\n",
    "#feature_importance = gs.best_estimator_.feature_importances_\n",
    "#sorted_idx = np.argsort(feature_importance)\n",
    "#pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "#plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "#plt.yticks(pos, feature_names[sorted_idx])\n",
    "#feature_names[sorted_idx]\n",
    "#plt.show()\n",
    "\n",
    "print(\"XGBOOST without SMOTE feature importance\")\n",
    "feature_importance = gs.best_estimator_.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(10,fig_length/3))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, feature_names[sorted_idx])\n",
    "feature_names[sorted_idx]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_kappa(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred, sample_weight=None)\n",
    "    return kappa\n",
    "\n",
    "def evaluate_recall(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    return recall\n",
    "\n",
    "def evaluate_precision(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    return precision\n",
    "\n",
    "def evaluate_con_mat_row(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    return (tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgbm_smote_accuracy = evaluate_accuracy(gs_smote,test_features,test_target)\n",
    "#gbm_smote_accuracy = evaluate_accuracy(gbm_smote,test_features,test_target)\n",
    "#rf_smote_accuracy = evaluate_accuracy(rf_smote,test_features,test_target)\n",
    "#ada_smote_accuracy = evaluate_accuracy(ada_smote,test_features,test_target)\n",
    "#tf_smote_accuracy = evaluate_accuracy(model_smote,test_features,test_target)\n",
    "xgbm_accuracy = evaluate_accuracy(gs,test_features,test_target)\n",
    "gbm_accuracy = evaluate_accuracy(gbm,test_features,test_target)\n",
    "rf_accuracy = evaluate_accuracy(rf,test_features,test_target)\n",
    "ada_accuracy = evaluate_accuracy(ada,test_features,test_target)    \n",
    "tf_accuracy = evaluate_accuracy(model,test_features,test_target)\n",
    "\n",
    "#xgbm_smote_kappa = evaluate_kappa(gs_smote,test_features,test_target)\n",
    "#gbm_smote_kappa = evaluate_kappa(gbm_smote,test_features,test_target)\n",
    "#rf_smote_kappa = evaluate_kappa(rf_smote,test_features,test_target)\n",
    "#ada_smote_kappa = evaluate_kappa(ada_smote,test_features,test_target)\n",
    "#tf_smote_kappa = evaluate_kappa(model_smote,test_features,test_target)\n",
    "xgbm_kappa = evaluate_kappa(gs,test_features,test_target)\n",
    "gbm_kappa = evaluate_kappa(gbm,test_features,test_target)\n",
    "rf_kappa = evaluate_kappa(rf,test_features,test_target)\n",
    "ada_kappa = evaluate_kappa(ada,test_features,test_target)\n",
    "tf_kappa = evaluate_kappa(model,test_features,test_target)  \n",
    "\n",
    "#xgbm_smote_recall = evaluate_recall(gs_smote,test_features,test_target)\n",
    "#gbm_smote_recall = evaluate_recall(gbm_smote,test_features,test_target)\n",
    "#rf_smote_recall = evaluate_recall(rf_smote,test_features,test_target)\n",
    "#ada_smote_recall = evaluate_recall(ada_smote,test_features,test_target)\n",
    "#tf_smote_recall = evaluate_recall(model_smote,test_features,test_target)\n",
    "xgbm_recall = evaluate_recall(gs,test_features,test_target)\n",
    "gbm_recall = evaluate_recall(gbm,test_features,test_target)\n",
    "rf_recall = evaluate_recall(rf,test_features,test_target)\n",
    "ada_recall = evaluate_recall(ada,test_features,test_target)\n",
    "tf_recall = evaluate_recall(model,test_features,test_target)  \n",
    "\n",
    "#xgbm_smote_precision = evaluate_precision(gs_smote,test_features,test_target)\n",
    "#gbm_smote_precision = evaluate_precision(gbm_smote,test_features,test_target)\n",
    "#rf_smote_precision = evaluate_precision(rf_smote,test_features,test_target)\n",
    "#ada_smote_precision = evaluate_precision(ada_smote,test_features,test_target)\n",
    "#tf_smote_precision = evaluate_precision(model_smote,test_features,test_target)\n",
    "xgbm_precision = evaluate_precision(gs,test_features,test_target)\n",
    "gbm_precision = evaluate_precision(gbm,test_features,test_target)\n",
    "rf_precision = evaluate_precision(rf,test_features,test_target)\n",
    "ada_precision = evaluate_precision(ada,test_features,test_target)\n",
    "tf_precision = evaluate_precision(model,test_features,test_target) \n",
    "\n",
    "#xgbm_smote_tfft = evaluate_con_mat_row(gs_smote,test_features,test_target)\n",
    "#gbm_smote_tfft = evaluate_con_mat_row(gbm_smote,test_features,test_target)\n",
    "#rf_smote_tfft = evaluate_con_mat_row(rf_smote,test_features,test_target)\n",
    "#ada_smote_tfft = evaluate_con_mat_row(ada_smote,test_features,test_target)\n",
    "#tf_smote_tfft = evaluate_con_mat_row(model_smote,test_features,test_target)\n",
    "xgbm_tfft = evaluate_con_mat_row(gs,test_features,test_target)\n",
    "gbm_tfft = evaluate_con_mat_row(gbm,test_features,test_target)\n",
    "rf_tfft = evaluate_con_mat_row(rf,test_features,test_target)\n",
    "ada_tfft = evaluate_con_mat_row(ada,test_features,test_target)\n",
    "tf_tfft = evaluate_con_mat_row(model,test_features,test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = [#{'model': 'XGBM_smote', 'accuracy': xgbm_smote_accuracy, 'kappa': xgbm_smote_kappa,'recall': xgbm_smote_recall, 'precision': xgbm_smote_precision,'tn, fp, fn, tp': xgbm_smote_tfft},\n",
    "          #{'model': 'GBM_smote', 'accuracy': gbm_smote_accuracy, 'kappa': gbm_smote_kappa,'recall': gbm_smote_recall, 'precision': gbm_smote_precision,'tn, fp, fn, tp': gbm_smote_tfft},\n",
    "          #{'model': 'RF_smote',  'accuracy': rf_smote_accuracy, 'kappa': rf_smote_kappa,'recall': rf_smote_recall, 'precision': rf_smote_precision,'tn, fp, fn, tp': rf_smote_tfft},\n",
    "          #{'model': 'ADA_smote', 'accuracy': ada_smote_accuracy, 'kappa': ada_smote_kappa, 'recall': ada_smote_recall, 'precision': ada_smote_precision ,'tn, fp, fn, tp': ada_smote_tfft },\n",
    "          #{'model': 'tf_smote', 'accuracy': tf_smote_accuracy,  'kappa': tf_smote_kappa,'recall': tf_smote_recall, 'precision': tf_smote_precision ,'tn, fp, fn, tp': tf_smote_tfft }]#,\n",
    "          {'model': 'XGBM', 'accuracy': xgbm_accuracy, 'kappa': xgbm_kappa, 'recall': xgbm_recall, 'precision': xgbm_precision,'tn, fp, fn, tp': xgbm_tfft},\n",
    "          {'model': 'GBM', 'accuracy': gbm_accuracy, 'kappa': gbm_kappa, 'recall': gbm_recall, 'precision': gbm_precision, 'tn, fp, fn, tp': gbm_tfft},\n",
    "          {'model': 'RF',  'accuracy': rf_accuracy, 'kappa': rf_kappa, 'recall': rf_recall, 'precision': rf_precision, 'tn, fp, fn, tp': rf_tfft},\n",
    "          {'model': 'ADA', 'accuracy': ada_accuracy, 'kappa': ada_kappa, 'recall': ada_recall, 'precision': ada_precision,  'tn, fp, fn, tp': ada_tfft },\n",
    "          {'model': 'tf', 'accuracy': tf_accuracy,  'kappa': tf_kappa, 'recall': tf_recall, 'precision': tf_precision ,'tn, fp, fn, tp': tf_smote_tfft }]\n",
    "df1 = pd.DataFrame(report)\n",
    "df1 = df1[['model', 'accuracy', 'kappa', 'recall', 'precision','tn, fp, fn, tp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot.bar(figsize=(df_length, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "import pickle\n",
    "\n",
    "# save GBM model to disk\n",
    "#filename1 = 'finalized_gbm_smote.sav'\n",
    "#pickle.dump(gbm_smote, open(filename1, 'wb'))\n",
    "\n",
    "# save RF model to disk\n",
    "#filename2 = 'finalized_rf_smote.sav'\n",
    "#pickle.dump(rf_smote, open(filename2, 'wb'))\n",
    "\n",
    "# save Adaboost model to disk\n",
    "#filename3 = 'finalized_ada_smote.sav'\n",
    "#pickle.dump(ada_smote, open(filename3, 'wb'))\n",
    "\n",
    "# save GBM model to disk\n",
    "filename4 = 'finalized_gbm.sav'\n",
    "pickle.dump(gbm, open(filename4, 'wb'))\n",
    "\n",
    "# save RF model to disk\n",
    "filename5 = 'finalized_rf.sav'\n",
    "pickle.dump(rf, open(filename5, 'wb'))\n",
    "\n",
    "# save Adaboost model to disk\n",
    "filename6 = 'finalized_ada.sav'\n",
    "pickle.dump(ada, open(filename6, 'wb'))\n",
    "\n",
    "################XGBoost model save\n",
    "# save XGB_smote model to disk\n",
    "#filename1x_smote = 'finalized_xgb_smote.sav'\n",
    "#pickle.dump(gs_smote, open(filename1x_smote, 'wb'))\n",
    "\n",
    "# save XGB model to disk\n",
    "filename1x = 'finalized_xgb.sav'\n",
    "pickle.dump(gs, open(filename1x, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "#model_smote_json = model_smote.model.to_json()\n",
    "#with open(\"model_smote_json.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_smote_json)\n",
    "# serialize weights to HDF5\n",
    "#model_smote.model.save_weights(\"model_smote_json.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.model.to_json()\n",
    "with open(\"model_json.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.model.save_weights(\"model_json.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
